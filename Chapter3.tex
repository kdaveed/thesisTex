\chapter{Problem Statement}


This chapter is divided into three sections. As the application is highly dependent on the underlying data model, the first section is dedicated to the data scheme describing the investigations in scope. The second chapter in turn addresses the problem of web applications that allows the creation of RDF data explained in the first section. It covers the issues of both the client and server side implementation and their communication. Finally section \ref{33} outlines the scheme of the solution proposed and implemented by the thesis work.


\section{Modeling anthropological research activity} \label{ps1}


This section consist of three subsections. The first two (\ref{331} and \ref{332}) describes how the RDFBones ontology (developed during the project) integrates the \textit{FMA} and \textit{OBI} ontologies for describing research processes related to anthropology. While the third section (\ref{333}) discusses how can the core ontology be extended to define custom bone segments and processes.


\subsection{Data on skeletal remains} \label{331}


We have seen in section \ref{fma} the base structure of the human skeleton. The most important point is that not only individual bones will be represented in the data we create, but the skeletal regions as well, like skull or vertebral column. The institute where these investigations are conducted posses mainly  skeletal remains of skulls. The skull has the peculiarity that it does not consists directly of bones organs, but from two sub skeletal divisions, and these two subdivisions contain the bone organs. \figref{tripleSkull} shows the ontology subset for the skull and the data instances (each denoted with \#). The red arrows denotes restrictions on the properties \textit{fma:systemic\_part\_of}.  

\img{\III}{rdfSkull.png}{Ontology and triples of the skull}{tripleSkull} 

So we know how skull and its subdivisions and bone organs are represented by RDF, but there are processes where specific bone segments have to be addressed as well. Therefor RDFBones have the class \textit{rdfbones:SegmentOfSkeletalElement}. This instances of this class is connected to the instances of the class \textit{Bone Organ} with the property \textit{fma:regional\_part\_of}.

\img{\III}{rdfBonesCard.png}{Bone segment in RDFBones}{rdfBonesCard} 

Furthermore these instances representing skeletal remains do not stay in the database individually. If a researcher takes a specific skull from the collection of the institute, it makes a so-called skeletal inventory, which records what bones segments are complete, partly present or missing. To store these information in the RDFBones ontology introduces three further classes (above the one for bone segment), which are all the subclasses of \textit{OBI} classes. 


\img{\III}{core.png}{RDFBones as extension of OBI}{rdfBonesCard} 

\figref{case1} illustrates the dataset through a simple problem. The upper left part of the figure shows that a specific bone is divided into three bone segments, while the right shows the existing bone from which the data has to be stored. It can be seen the section I. is complete, section II. is just partly present and the III. is missing. The lower part of the figure then shows that the three segment are represented as subclass of the \textit{:SegmentOfSkeletalElement} class (denoted with blue), and from the third type there are no instance have been created, while the first two are connected to the skeletal inventory and compleness label instances through \textit{:Completeness2States} instances. 

\img{\III}{case1.png}{Custom bone segment example}{case1} 


This is the way how the information is stored about skeletal remains using the RDFBones ontology.


\subsection{Investigation process}\label{332}


An investigation is done by execution of the a study design. It has three parts, the assay, the data transformation and the drawing of a conclusion. From assays and data transformations there can be more in one execution, but there is only one conclusion. The inputs of the assays are always segments of skeletal elements, an their output is always a measurement datum, while the data transformation's  input and output are both measurement datums.

\img{\III}{rdfBonesO.png}{Applied subset of OBI ontology}{rdfBonesO} 


To understand a bit more what this data model can be actually used, let us take the example of an investigation, whose goal is to determine if a taken skull belonged to a male or female. The basis is that the male and female skeleton has different peculiarities that can be quantified, how expressed they are. \figref{glabella} illustrates an example the token \textit{Glabella}, which is on the \textit{Nasal bone}, and its expressions.  

\img{\III}{glabExpressions.png}{Glabella and its expressions}{glabella}


The larger the numbers for masculine and the lowers are feminine expression. An assay in this case is an assignment of a scalar value to a bone segment. The investigation process does not take only one bone segment but several different ones, to reduce the possibility of the erroneous output. \figref{sde} shows a dataset of a study design execution where the green arrows stand for \textit{has specified input} and the blue ones for the \textit{has specified output} predicates. The idea is simple, the output of the assays are aggregated, and if the output is smaller then zero then it was a male, otherwise a female.

\img{\III}{sde.png}{Study design execution dataset}{sde} 


Where the light grey boxes are the instances of \textit{Assay}, \textit{Data Transformation} and \textit{Drawing conclusion} classes respectively.


\subsection{Ontology Extensions} \label{333}



\imgK{\III}{siExt.png}{Ontology extension for skeletal inventories}

\imgK{\III}{extensionAssay.png}{Ontology extension for sex estimation}



\section{RDF Data input}

\subsection{Multi dimensional form}

As it was addressed in the previous section each data input process of the application can be modeled by means of a tree style data structure. This means in terms of the data of the form, that just single key-value pairs like by the static HTML form is not sufficient for the problem. Therefore the task is provide such an interface that allows the user to add dynamically subforms, whose data object will be stored in arrays. \figref{mdfl} illustrates the idea of the structure. 

\img{\III}{multiDimensionalForm.png}{Multi dimensional form layout}{mdfl}

So the forms consist of the selectors, and literalfield explained in the Chapter 1., but with an additional element that add further subforms. To achieve this JavaScript routine is required that adds the elements automatically and fills the form object with the data. The produced data of the form is looks as follows.


\begin{lstlisting}[captionpos=b, caption=JSON object of the form, label=3rd:sparql,
basicstyle=\footnotesize,frame=single]
{
	key1 : "value1",
	key2 : "value2",
	...
	subFormKey1 : [
	{
		key1_1 : "value1_1",
		...				
	}, { ... }]
}
\end{lstlisting}





\begin{lstlisting}[captionpos=b, caption= data representing skull, label=skullJSON,
basicstyle=\footnotesize,frame=single]
{
skeletalSubdivisionUri : "FMA:46565",
sytemic_parts : [{
uri : "FMA:53672",
systemic_parts : [{
uri : "FMA:52788",  //Right parietal bone
} , { ... }]
} , { ... }
]	
}
\end{lstlisting}



\subsection{Form dependencies} \label{formDependencies}


\img{\III}{subformDependency.png}{Subform dependencies}{mdfl}

These dependencies can occur not only between subforms but as well by in form dependencies where the selector elements can change based on selections.

\subsection{Instance browsing}


\begin{itemize}
	\item Figure ~\ref{navigator3} shows a further option for instance selection. 
\end{itemize}

\img{\III}{navigator.png}{Navigator example}{navigator3}

\begin{itemize}
	\item The implementation requires on the server side query and the grouping of the result
	\item Client side - programming the navigator window
\end{itemize}


\subsection{Validation}

As by each form there is required field - required - restrictions
The client has to get the information, about restrictions, and so  


\subsection{Editing form data}
	
As it was already addressed in section \ref{vivoCef}, the dataset created by the forms have to be edited as well. By editing, the HTTP request calling the entry form contains an additional field, namely the \textit{objectUri}. Based on the data model of the form, the server has to prepare the dataset, in our case a JSON object. The challenge of the server implementation is that in such multi dimensional dataset, it is not sufficient to perform only one query for the whole form data.

\img{\III}{exampleDataModel.png}{Example data model}{exDatMod}

\begin{lstlisting}[captionpos=b, caption=SPARQL query for the form data, label={sparqlExisting},
basicstyle=\footnotesize,frame=single]
SELECT ?a ?b
WHERE {
	?objectUri		p1		?a .
	?objectUri		p2		?b .
	FILTER ( ?objectUri = <inputParameter>)
}
\end{lstlisting}

The example data model from \figref{exDatMod} helps to understand the problem in more detail. If the SPARQL query on \listref{sparqlExisting} for variables ?a and ?b with incoming \textit{objectUri} value were executed, then result table of the query is inconvenient to process. For example if there are two instances for both ?a and ?b present in the dataset, then the result table contains \textit{2 x 2 = 4} elements (\tableref{sparqlResult}).

\begin{table}

	\begin{center}
		\begin{tabular}{||c | c||} 
			\hline
			?a & ?b  \\ [0.5ex] 
			\hline\hline
			a1 & b1 \\ 
			\hline
			a1 & b2 \\
			\hline
			a2 & b1 \\
			\hline
			a2 & b2 \\ [1ex] 
			\hline 
		\end{tabular}
	\end{center}
	\caption{SPARQL Result}  \label{sparqlResult}
\end{table}


Therefore the data object of the form has to be retrieved gradually, by dividing the data model graph by the predicates, whose cardinality is larger than one.

The next step after that the server has prepared the multi dimensional JSON object for the client, is to restore the state of the form, in which it was submitted by the user. This requires firstly the filling of the fields with the existing values, and adding the sub forms based on the arrays. Secondly the options of the selectors must be loaded, so that they conform to the dependencies explained in section \ref{formDependencies}. 

Finally if a value of selector or literal field changes, or new sub forms has to be added or removed, the entry form data should not be completely sent again to the server, but only the data fields that are concerned by the modification. Thus it does not require a complete page reload, and these operation can be performed through AJAX calls. To achieve this the client has to be prepared to be able to send data modification requests to the server on change event of any form element or sub form.

\subsection{Saving data}




\section{Solution Scheme} \label{33}








