

\chapter{Conclusion}

\section{Evaluation}

The applied VIVO framework offered the possibility to define data input processes in a declarative way to some limited extent, by defining the elements of the input form and the RDF graph pattern. The simplicity lied in that VIVO allowed the setting of literals of particular instances, which required only static HTML forms and simple value substitution algorithms. However during the \textit{RDFBones} project the emphasis was not on the literals but on the instances, and there were such cases where multiple instance had to be created through one data entry form. This required dynamic interfaces with some handler algorithm, instead of static form elements, and the server routines had to become more complex too. Important challenge moreover that rules regarding which entity belongs to which was declared in ontology extension, and these definition had influenced the interface layout.

During thesis the VIVO idea were further developed, so that the system can cope with the more complex problems. To achieve that the individual cases can be solved without coding rapidly, an extended vocabulary were designed that is able to express the problems of multi level data input, an the code library were developed for the client and the server that were able to manage the advanced functionality based on a certain descriptor dataset. In the vocabulary related to the data definition the most important advancement is that it is possible to express if a the subject and the object of a particular triple in the graph pattern are in one-to-one or in one-to-many relationship with each other (\textit{Triple} vs. \textit{MultiTriple}). On the form definition this cardinality related definition is reflected by the sub forms (\textit{SubformAdder}). These elements allowed the expression of forms and data processor routines that can handle multi dimensional dataset. Further improvement that vocabulary for data definition does not relate only to the RDF triples that were supposed to be stored, but to RDF triples as well which contained description of the system, namely the OWL restriction in the ontology extensions (\textit{RestrictionTriple}). The utility of that definition it connects RDF nodes that were represented on the interface, thus the dependency between form elements could be expressed as well in a declarative way. From the restriction triples the appropriate SPARQL queries are generated and the client and server algorithm through AJAX calls could realize the adaptive interface. Finally, we have seen that the resulting RDF dataset do not necessarily consists of new instance, but existing instance can be selected. The developed vocabulary is able to express these requirements as well, and can allow the convenient browsing and selection of them with further form elements (\textit{AuxNodeSelector}, \textit{InstanceSelector}). 


The main benefit of the system that it abstracts from the low level implementation details, and the developer does not have to care about how the data created, edited and deleted by the application. It is sufficient to think about the scheme, the constraints and mapping to the interface of the data describing a particular entity, and the generic client and server libraries realizes the data flow between the user and database. The system can be applied then for any kind of problems where the rules of the system lies in ontological statements. Moreover due to the dynamic VIVO profile page, which allows the discovery of the RDF data graph, the created instances can be browsed without additional programming, and their literal values can be set through custom entry forms developed with the original VIVO framework tools. So the implemented system embedded into VIVO offers a widely employable Semantic Web based data management application.


\section{Future work}


